<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>postprocessing.correlation API documentation</title>
<meta name="description" content="Base correlation function." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>postprocessing.correlation</code></h1>
</header>
<section id="section-intro">
<p>Base correlation function.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># This file is part of atooms
# Copyright 2010-2018, Daniele Coslovich

&#34;&#34;&#34;Base correlation function.&#34;&#34;&#34;

import os
import logging
from collections import defaultdict

import numpy
from atooms.trajectory import Trajectory
from atooms.trajectory.decorators import Unfolded, fold
from atooms.trajectory.decorators import change_species
from atooms.system.particle import distinct_species
from atooms.core.utils import Timer
try:
    from medepy.metadata import dump as _dump
except ImportError:
    from .helpers import _dump

from . import core
from .helpers import adjust_skip
from .progress import progress

__all__ = [&#39;acf&#39;, &#39;gcf&#39;, &#39;gcf_offset&#39;, &#39;Correlation&#39;]

_log = logging.getLogger(__name__)


def acf(grid, skip, t, x):
    &#34;&#34;&#34;
    Auto correlation function.

    Calculate the correlation between time t(i0) and t(i0+i)
    for all possible pairs (i0,i) provided by grid.
    &#34;&#34;&#34;
    cf = defaultdict(float)
    cnt = defaultdict(int)
    xave = numpy.average(x)
    for i in grid:
        for i0 in range(0, len(x)-i, skip):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += (x[i0+i]-xave) * (x[i0]-xave)
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt], cnt


def gcf(f, grid, skip, t, x):
    &#34;&#34;&#34;
    Generalized auto-correlation function &lt;f(x[i], x[i0])&gt;

    Pass a function `f` to apply to the data at each frame.

    Exemple: mean square displacement.
    &#34;&#34;&#34;
    # Calculate the correlation between time t(i0) and t(i0+i)
    # for all possible pairs (i0,i) provided by grid
    cf = defaultdict(float)
    cnt = defaultdict(int)
    for i in grid:
        # Note: len(x) gives x.shape[0]
        for i0 in progress(range(0, len(x)-i-1, skip)):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += f(x[i0+i], x[i0])
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt], [cnt[ti] for ti in dt]


def gcf_offset(f, grid, skip, t, x):
    &#34;&#34;&#34;
    Generalized auto-correlation function &lt;f(x[i], x[i0])&gt; using a grid with offsets

    Pass a function `f` to apply to the data `x` at each frame.

    Exemple: mean square displacement.
    &#34;&#34;&#34;
    # Calculate the correlation between time t(i0) and t(i0+i)
    # for all possible pairs (i0,i) provided by grid
    cf = defaultdict(float)
    cnt = defaultdict(int)
    # Standard calculation
    for off, i in progress(grid, total=len(grid)):
        for i0 in range(off, len(x)-i, skip):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += f(x[i0+i], x[i0])
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt]


def _subtract_mean(weight):
    mean = 0
    for current_field in weight:
        mean += current_field.mean()
    mean /= len(weight)
    for current_field in weight:
        current_field -= mean
    return weight


def _is_iterable(maybe_iterable):
    try:
        iter(maybe_iterable)
    except TypeError:
        return False
    else:
        return True


class Correlation(object):
    &#34;&#34;&#34;
    Base class for correlation functions.

    The correlation function is calculated for the trajectory `trj`. This can be:

    - an object implementing the atooms `Trajectory` interface
    - the path to a trajectory file in a format recognized by atooms

    A correlation function A(x) is defined over a grid of real
    entries {x_i} given by the list `grid`. To each entry of the grid,
    the correlation function has a corresponding value A_i=A(x_i). The
    latter values are stored in the `value` list.

    Correlation functions that depend on several variables, A(x,y,...)
    must provide a list of grids, one for each variable. The order is
    one specified by the `symbol` class variable, see below.

    The correlation function A is calculated as a statistical average
    over several time origins in the trajectory `trj`. The `norigins`
    variable can be used to tune the number of time origins used to
    carry out the average. `norigins` can take the following values:

    - `norigins=-1`: all origins are used
    - an integer &gt;= 1: use only `n_origins` time origins
    - a float in the interval (0,1): use only a fraction `norigins` of frames as time origins
    - `None`: a heuristics is used to keep the product of steps times particles constant

    Subclasses must provide a symbolic expression of the correlation
    function through the `symbol` class variable. The following
    convention is used: if a correlation function A depends on
    variables x and y, then `symbol = &#39;A(x,y)&#39;`.

    The `phasespace` variable allow subclasses to access a list of 2d
    numpy arrays with particles coordinates via the following private
    variables:

    - if `nbodies` is 1: `self._pos` for positions, `self._vel` for
    velocities, `self._unf_pos` for PBC-unfolded positions

    - if `nbodies` is 2, an additional suffix that take values 0 or 1
    is added to distinguish the two sets of particles,
    e.g. `self._pos_0` and `self._pos_1`
    &#34;&#34;&#34;

    nbodies = 1
    &#34;&#34;&#34;
    Class variable that controls the number of bodies, i.e. particles,
    associated to the correlation function. This variable controls the
    internal arrays used to compute the correlation, see `phasespace`.
    &#34;&#34;&#34;
    static = False
    &#34;&#34;&#34;
    Turn this to `True` is the correlation function is static,
    i.e. not time-dependent. This may enable some optimizations.
    &#34;&#34;&#34;
    symbol = &#39;&#39;
    &#34;&#34;&#34;Example: fskt&#34;&#34;&#34;
    short_name = &#39;&#39;
    &#34;&#34;&#34;Example: F_s(k,t)&#34;&#34;&#34;
    long_name = &#39;&#39;
    &#34;&#34;&#34;Example: Self intermediate scattering function&#34;&#34;&#34;
    phasespace = [&#39;pos&#39;, &#39;pos-unf&#39;, &#39;vel&#39;]
    &#34;&#34;&#34;
    List of strings or string among [&#39;pos&#39;, &#39;pos-unf&#39;, &#39;vel&#39;]. It
    indicates which variables should be read from the trajectory file.
    They will be available as self._pos, self._pos_unf, self._vel.
    &#34;&#34;&#34;
    _symmetric = True
    &#34;&#34;&#34;
    If nbodies&gt;1, a symmetric correlation function is invariant under
    the exchange between _pos_0 and _pos_1. In that case, _symmetric
    is True.
    &#34;&#34;&#34;

    def __init__(self, trj, grid, output_path=None, norigins=None, fix_cm=False):
        # Accept a trajectory-like instance or a path to a trajectory
        if isinstance(trj, str):
            self.trajectory = Trajectory(trj, mode=&#39;r&#39;, fmt=core.pp_trajectory_format)
        else:
            self.trajectory = trj
        self._fix_cm = fix_cm
        self._unfolded = None
        self.grid = grid
        self.value = []
        self.analysis = {}
        self.comments = None  # can be modified by user at run time
        self.tag = &#39;&#39;
        self.tag_description = &#39;the whole system&#39;
        if self.trajectory.filename is None:
            self.output_path = None
        else:
            self.output_path = output_path if output_path is not None else core.pp_output_path
        self.skip = adjust_skip(self.trajectory, norigins)

        # Callbacks
        self._cbk = []
        self._cbk_args = []
        self._cbk_kwargs = []

        # Lists for one body correlations
        self._pos = []
        self._vel = []
        self._ids = []
        self._pos_unf = []

        # Lists for two-body correlations
        self._pos_0, self._pos_1 = [], []
        self._vel_0, self._vel_1 = [], []
        self._ids_0, self._ids_1 = [], []
        self._pos_unf_0, self._pos_unf_1 = [], []

        # Weights
        self._weight = None
        self._weight_0, self._weight_1 = None, None
        self._weight_field = None
        self._weight_fluctuations = False

    def __str__(self):
        return &#39;{} at &lt;{}&gt;&#39;.format(self.long_name, id(self))

    def add_weight(self, trajectory=None, field=None, fluctuations=False):
        &#34;&#34;&#34;
        Add weight from the given `field` in `trajectory`

        If `trajectory` is `None`, `self.trajectory` will be used and
        `field` must be a particle property.

        If `field` is `None`, `trajectory` is assumed to be a path an
        xyz trajectory and we use the data in last column as a weight.

        If both `field` and `trajectory` are `None` the function
        returns immediately and the weight is not set.

        The optional `fluctuations` option subtracts the mean,
        calculated from the ensemble average, from the weight.
        &#34;&#34;&#34;
        if trajectory is None and field is None:
            return

        self._weight = []
        self._weight_fluctuations = fluctuations

        # Guessing the field from the last column of an xyz file is
        # not supported anymore
        if field is None:
            raise ValueError(&#39;provide field to use as weight&#39;)
        else:
            self._weight_field = field

        # By default we use the same trajectory as for the phasespace
        if trajectory is None:
            self._weight_trajectory = self.trajectory
        else:
            self._weight_trajectory = trajectory
            # Copy over the field
            from .helpers import copy_field
            self.trajectory.add_callback(copy_field, self._weight_field, self._weight_trajectory)

        # Make sure the steps are consistent
        if self._weight_trajectory.steps != self.trajectory.steps:
            raise ValueError(&#39;inconsistency between weight trajectory and trajectory&#39;)

        # Modify tag
        fluct = &#39;fluctuations&#39; if self._weight_fluctuations else &#39;&#39;
        self.tag_description += &#39; with {} {} field&#39;.format(self._weight_field.replace(&#39;_&#39;, &#39; &#39;), fluct)
        self.tag_description = self.tag_description.replace(&#39;  &#39;, &#39; &#39;)
        self.tag += &#39;.{}_{}&#39;.format(self._weight_field, fluct)
        self.tag.strip(&#39;_.&#39;)

    def add_filter(self, cbk, *args, **kwargs):
        &#34;&#34;&#34;Add filter callback `cbk` along with positional and keyword arguments&#34;&#34;&#34;
        if len(self._cbk) &gt; self.nbodies:
            raise ValueError(&#39;number of filters cannot exceed n. of bodies&#39;)
        self._cbk.append(cbk)
        self._cbk_args.append(args)
        self._cbk_kwargs.append(kwargs)

    def need_update(self):
        &#34;&#34;&#34;Check if the trajectory file is newer than the output file&#34;&#34;&#34;
        need = True
        if os.path.exists(self._output_file) and self._output_file != &#39;/dev/stdout&#39;:
            if os.path.getmtime(self.trajectory.filename) &lt; \
               os.path.getmtime(self._output_file):
                need = False
        return need

    def _setup_arrays(self):
        &#34;&#34;&#34;
        Dump positions and/or velocities at different time frames as a
        list of numpy array.
        &#34;&#34;&#34;
        # TODO: what happens if we call compute twice?? Shouldnt we reset the arrays?
        # Ensure phasespace is a list.
        # It may not be a class variable anymore after this
        if not isinstance(self.phasespace, list) and \
           not isinstance(self.phasespace, tuple):
            self.phasespace = [self.phasespace]

        # Setup arrays
        if self.nbodies == 1:
            self._setup_arrays_onebody()
            self._setup_weight_onebody()
        elif self.nbodies == 2:
            self._setup_arrays_twobody()
            self._setup_weight_twobody()

    def _setup_arrays_onebody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for one-body correlations.

        We also take care of dumping the weight if needed, see
        `add_weight()`.
        &#34;&#34;&#34;
        # Local shortcut
        th = self.trajectory

        # We unfold the trajectory if phasespace requests it and
        # unfolded positions are not available in the trajectory, or
        # if we request folded positions with fixed center of mass
        if (&#39;pos-unf&#39; in self.phasespace and not hasattr(th[0].particle[0], &#39;position_unfolded&#39;)) or \
           (&#39;pos&#39; in self.phasespace and self._fix_cm):
            # We unfold the positions, caching the trajectory
            if self._unfolded is None:
                self._unfolded = Unfolded(self.trajectory, fixed_cm=self._fix_cm)
                # We must fold positions back in this case
                if &#39;pos&#39; in self.phasespace:
                    self._unfolded.add_callback(fold)
            # Change the local shortcut to the unfolded trajectory
            th = self._unfolded

        # Read everything except unfolded trajectories
        if &#39;pos&#39; in self.phasespace or &#39;vel&#39; in self.phasespace or &#39;ids&#39; in self.phasespace:
            ids = distinct_species(th[0].particle)
            for s in progress(th):
                # Apply filter if there is one
                if len(self._cbk) &gt; 0:
                    s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                if &#39;pos&#39; in self.phasespace:
                    self._pos.append(s.dump(&#39;pos&#39;))
                if &#39;vel&#39; in self.phasespace:
                    self._vel.append(s.dump(&#39;vel&#39;))
                if &#39;ids&#39; in self.phasespace:
                    _ids = s.dump(&#39;species&#39;)
                    _ids = numpy.array([ids.index(_) for _ in _ids], dtype=numpy.int32)
                    self._ids.append(_ids)

        # Read unfolded positions if requested
        if &#39;pos-unf&#39; in self.phasespace:
            if hasattr(th[0].particle[0], &#39;position_unfolded&#39;):
                # Unfolded positions are present in the trajectory
                for s in progress(th):
                    # Fixing the CM must be done explicitly using
                    # particle.position_unfolded because atooms.system
                    # methods work with particle.position
                    # TODO: can be revised with atooms 3.4.0
                    if self._fix_cm:
                        # Compute CM using unfolded positions, which is safe
                        cm = numpy.zeros_like(s.particle[0].position_unfolded)
                        mtot = 0.0
                        for p in s.particle:
                            cm += p.position_unfolded * p.mass
                            mtot += p.mass
                        cm /= mtot
                        # Subtract it
                        for p in s.particle:
                            p.position_unfolded -= cm
                    # Apply filter if there is one
                    # This must be done after the CM has been fixed
                    if len(self._cbk) &gt; 0:
                        s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                    self._pos_unf.append(s.dump(&#39;particle.position_unfolded&#39;))
            else:
                for s in progress(th):
                    # Apply filter if there is one
                    if len(self._cbk) &gt; 0:
                        s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                    self._pos_unf.append(s.dump(&#39;pos&#39;))

    def _setup_weight_onebody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for the weight, see `add_weight()`
        &#34;&#34;&#34;
        if self._weight is None:
            return

        # Dump arrays of weights
        for s in progress(self.trajectory):
            # Apply filter if there is one
            # TODO: fix when weight trajectory does not contain actual particle info
            # It should be possible to link the weight trajectory to the trajectory
            # and return the trajectory particles with the weight
            if len(self._cbk) &gt; 0:
                s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
            current_weight = s.dump(&#39;particle.%s&#39; % self._weight_field)
            self._weight.append(current_weight)

        # Subtract global mean
        if self._weight_fluctuations:
            _subtract_mean(self._weight)

    def _setup_weight_twobody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for the weight, see `add_weight()`
        &#34;&#34;&#34;
        if self._weight is None:
            return

        self._weight = []
        self._weight_0 = []
        self._weight_1 = []

        # TODO: add checks on number of filters
        if len(self._cbk) &lt;= 1:
            self._setup_weight_onebody()
            self._weight_0 = self._weight
            self._weight_1 = self._weight
            return

        # Dump arrays of weights
        for s in progress(self.trajectory):
            # Apply filters
            if len(self._cbk) == 2:
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
            self._weight_0.append(s0.dump(&#39;particle.%s&#39; % self._weight_field))
            self._weight_1.append(s1.dump(&#39;particle.%s&#39; % self._weight_field))

        # Subtract global mean
        if self._weight_fluctuations:
            _subtract_mean(self._weight_0)
            _subtract_mean(self._weight_1)

    def _setup_arrays_twobody(self):
        &#34;&#34;&#34;Setup list of numpy arrays for two-body correlations.&#34;&#34;&#34;
        if len(self._cbk) &lt;= 1:
            self._setup_arrays_onebody()
            self._pos_0 = self._pos
            self._pos_1 = self._pos
            self._vel_0 = self._vel
            self._vel_1 = self._vel
            self._ids_0 = self._ids
            self._ids_1 = self._ids
            return

        if &#39;pos&#39; in self.phasespace or &#39;vel&#39; in self.phasespace or &#39;ids&#39; in self.phasespace:
            ids = distinct_species(self.trajectory[0].particle)
            for s in progress(self.trajectory):
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
                if &#39;pos&#39; in self.phasespace:
                    self._pos_0.append(s0.dump(&#39;pos&#39;))
                    self._pos_1.append(s1.dump(&#39;pos&#39;))
                if &#39;vel&#39; in self.phasespace:
                    self._vel_0.append(s0.dump(&#39;vel&#39;))
                    self._vel_1.append(s1.dump(&#39;vel&#39;))
                if &#39;ids&#39; in self.phasespace:
                    _ids_0 = s0.dump(&#39;species&#39;)
                    _ids_1 = s1.dump(&#39;species&#39;)
                    _ids_0 = numpy.array([ids.index(_) for _ in _ids_0], dtype=numpy.int32)
                    _ids_1 = numpy.array([ids.index(_) for _ in _ids_1], dtype=numpy.int32)
                    self._ids_0.append(_ids_0)
                    self._ids_1.append(_ids_1)

        # Dump unfolded positions if requested
        if &#39;pos-unf&#39; in self.phasespace:
            for s in progress(Unfolded(self.trajectory)):
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
                self._pos_unf_0.append(s0.dump(&#39;pos&#39;))
                self._pos_unf_1.append(s1.dump(&#39;pos&#39;))

    def compute(self):
        &#34;&#34;&#34;
        Compute the correlation function.

        It wraps the _compute() method implemented by subclasses.
        This method sets the `self.grid` and `self.value` variables,
        which are also returned.
        &#34;&#34;&#34;
        _log.info(&#39;setup arrays for %s&#39;, self.tag_description)
        t = [Timer(), Timer()]
        t[0].start()
        self._setup_arrays()
        t[0].stop()

        _log.info(&#39;computing %s for %s&#39;, self.long_name, self.tag_description)
        _log.info(&#39;using %s time origins out of %s&#39;,
                  len(range(0, len(self.trajectory), self.skip)),
                  len(self.trajectory))
        t[1].start()
        self._compute()
        t[1].stop()

        _log.info(&#39;output file %s&#39;, self._output_file)
        _log.info(&#39;done %s for %s in %.1f sec [setup:%.0f%%, compute: %.0f%%]&#39;,
                  self.long_name,
                  self.tag_description, t[0].wall_time + t[1].wall_time,
                  t[0].wall_time / (t[0].wall_time + t[1].wall_time) * 100,
                  t[1].wall_time / (t[0].wall_time + t[1].wall_time) * 100)
        _log.info(&#39;&#39;)

        return self.grid, self.value

    def _compute(self):
        &#34;&#34;&#34;Subclasses must implement this&#34;&#34;&#34;
        pass

    def analyze(self):
        &#34;&#34;&#34;
        Subclasses may implement this and store the results in the
        self.analysis dictonary
        &#34;&#34;&#34;
        pass

    @property
    def _output_file(self):
        &#34;&#34;&#34;Returns path of output file&#34;&#34;&#34;
        # Interpolate the output path string
        if self.output_path is None:
            filename = None
        else:
            filename = self.output_path.format(symbol=self.symbol,
                                               short_name=self.short_name,
                                               long_name=self.long_name.replace(&#39; &#39;, &#39;_&#39;),
                                               tag=self.tag,
                                               tag_description=self.tag_description.replace(&#39; &#39;, &#39;_&#39;),
                                               trajectory=self.trajectory)
            # Strip unpleasant punctuation from basename path
            for punct in [&#39;.&#39;, &#39;_&#39;, &#39;-&#39;]:
                subpaths = filename.split(&#39;/&#39;)
                subpaths[-1] = subpaths[-1].replace(punct * 2, punct)
                subpaths[-1] = subpaths[-1].strip(punct)
                filename = &#39;/&#39;.join(subpaths)
        return filename

    def read(self):
        &#34;&#34;&#34;Read correlation function from existing file&#34;&#34;&#34;
        with open(self._output_file, &#39;r&#39;) as inp:
            x = numpy.loadtxt(inp, unpack=True)
            if len(x) == 3:
                _log.warn(&#34;cannot read 3-columns files yet in %s&#34;, self._output_file)
            elif len(x) == 2:
                self.grid, self.value = x
            else:
                self.grid, self.value = x[0: 2]
                _log.warn(&#34;Ignoring some columns in %s&#34;, self._output_file)

    @property
    def grid_name(self):
        &#34;&#34;&#34;
        Return the name of the grid variables

        Example:
        -------
        If `self.name` is `F_s(k,t)`, the function returns `[&#39;k&#39;, &#39;t&#39;]`
        &#34;&#34;&#34;
        variables = self.short_name.split(&#39;(&#39;)[1][:-1]
        return variables.split(&#39;,&#39;)

    def write(self):
        &#34;&#34;&#34;
        Write the correlation function and the analysis data to file

        The `output_path` instance variable is used to define the
        output files by interpolating the following variables:

        - symbol
        - short_name
        - long_name
        - tag
        - tag_description
        - trajectory

        The default is defined by core.pp_output_path, which currently
        looks like &#39;{trajectory.filename}.pp.{symbol}.{tag}&#39;
        &#34;&#34;&#34;
        # Pack grid and value into arrays to dump
        if _is_iterable(self.grid[0]) and len(self.grid) == 2:
            x = numpy.array(self.grid[0]).repeat(len(self.value[0]))
            y = numpy.array(self.grid[1] * len(self.grid[0]))
            z = numpy.array(self.value).flatten()
            dump = numpy.transpose(numpy.array([x, y, z]))
        else:
            dump = numpy.transpose(numpy.array([self.grid, self.value]))

        # Comment line
        # Extract variables from parenthesis in symbol
        variables = self.short_name.split(&#39;(&#39;)[1][:-1]
        variables = variables.split(&#39;,&#39;)
        columns = variables + [self.short_name]  # [self.symbol]
        if len(self.tag_description) &gt; 0:
            conj = &#39;of&#39;
        else:
            conj = &#39;&#39;
        comments = _dump(title=&#39;%s %s %s %s&#39; % (self.long_name, self.short_name, conj, self.tag_description),
                         columns=columns,
                         command=&#39;atooms-pp&#39;, version=core.__version__,
                         description=None, note=None,
                         parents=self.trajectory.filename,
                         inline=False)
        if self.comments is not None:
            comments += self.comments

        # Results of analysis
        analysis = &#34;&#34;
        for x, f in self.analysis.items():
            if f is not None:
                analysis += &#39;# %s: %s\n&#39; % (x, f)

        # Put it all together
        # and make sure the path to the output file exists
        import os
        from atooms.core.utils import mkdir
        if self._output_file is not None:
            mkdir(os.path.dirname(self._output_file))
            with open(self._output_file, &#39;w&#39;) as fh:
                fh.write(comments)
                if len(analysis) &gt; 0:
                    fh.write(analysis)
                numpy.savetxt(fh, dump, fmt=&#34;%g&#34;)
                fh.flush()

    def do(self, update=False):
        &#34;&#34;&#34;
        Do the full template pattern: compute, analyze and write the
        correlation function.
        &#34;&#34;&#34;
        if update and not self.need_update():
            self.read()
            return

        self.compute()

        try:
            self.analyze()
        except ImportError as e:
            _log.warn(&#39;Could not analyze due to missing modules, continuing...&#39;)
            _log.warn(e)

        self.write()

    def __call__(self):
        self.do()

    def show(self, now=True):
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            return

        if not _is_iterable(self.grid[0]):
            plt.plot(self.grid, self.value)
            plt.ylabel(self.short_name)
            plt.xlabel(self.grid_name[0])
        if now:
            plt.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="postprocessing.correlation.acf"><code class="name flex">
<span>def <span class="ident">acf</span></span>(<span>grid, skip, t, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Auto correlation function.</p>
<p>Calculate the correlation between time t(i0) and t(i0+i)
for all possible pairs (i0,i) provided by grid.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def acf(grid, skip, t, x):
    &#34;&#34;&#34;
    Auto correlation function.

    Calculate the correlation between time t(i0) and t(i0+i)
    for all possible pairs (i0,i) provided by grid.
    &#34;&#34;&#34;
    cf = defaultdict(float)
    cnt = defaultdict(int)
    xave = numpy.average(x)
    for i in grid:
        for i0 in range(0, len(x)-i, skip):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += (x[i0+i]-xave) * (x[i0]-xave)
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt], cnt</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.gcf"><code class="name flex">
<span>def <span class="ident">gcf</span></span>(<span>f, grid, skip, t, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Generalized auto-correlation function <f(x[i], x[i0])></p>
<p>Pass a function <code>f</code> to apply to the data at each frame.</p>
<p>Exemple: mean square displacement.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gcf(f, grid, skip, t, x):
    &#34;&#34;&#34;
    Generalized auto-correlation function &lt;f(x[i], x[i0])&gt;

    Pass a function `f` to apply to the data at each frame.

    Exemple: mean square displacement.
    &#34;&#34;&#34;
    # Calculate the correlation between time t(i0) and t(i0+i)
    # for all possible pairs (i0,i) provided by grid
    cf = defaultdict(float)
    cnt = defaultdict(int)
    for i in grid:
        # Note: len(x) gives x.shape[0]
        for i0 in progress(range(0, len(x)-i-1, skip)):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += f(x[i0+i], x[i0])
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt], [cnt[ti] for ti in dt]</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.gcf_offset"><code class="name flex">
<span>def <span class="ident">gcf_offset</span></span>(<span>f, grid, skip, t, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Generalized auto-correlation function <f(x[i], x[i0])> using a grid with offsets</p>
<p>Pass a function <code>f</code> to apply to the data <code>x</code> at each frame.</p>
<p>Exemple: mean square displacement.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gcf_offset(f, grid, skip, t, x):
    &#34;&#34;&#34;
    Generalized auto-correlation function &lt;f(x[i], x[i0])&gt; using a grid with offsets

    Pass a function `f` to apply to the data `x` at each frame.

    Exemple: mean square displacement.
    &#34;&#34;&#34;
    # Calculate the correlation between time t(i0) and t(i0+i)
    # for all possible pairs (i0,i) provided by grid
    cf = defaultdict(float)
    cnt = defaultdict(int)
    # Standard calculation
    for off, i in progress(grid, total=len(grid)):
        for i0 in range(off, len(x)-i, skip):
            # Get the actual time difference
            dt = t[i0+i] - t[i0]
            cf[dt] += f(x[i0+i], x[i0])
            cnt[dt] += 1

    # Return the ACF with the time differences sorted
    dt = sorted(cf.keys())
    return dt, [cf[ti] / cnt[ti] for ti in dt]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="postprocessing.correlation.Correlation"><code class="flex name class">
<span>class <span class="ident">Correlation</span></span>
<span>(</span><span>trj, grid, output_path=None, norigins=None, fix_cm=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for correlation functions.</p>
<p>The correlation function is calculated for the trajectory <code>trj</code>. This can be:</p>
<ul>
<li>an object implementing the atooms <code>Trajectory</code> interface</li>
<li>the path to a trajectory file in a format recognized by atooms</li>
</ul>
<p>A correlation function A(x) is defined over a grid of real
entries {x_i} given by the list <code>grid</code>. To each entry of the grid,
the correlation function has a corresponding value A_i=A(x_i). The
latter values are stored in the <code>value</code> list.</p>
<p>Correlation functions that depend on several variables, A(x,y,&hellip;)
must provide a list of grids, one for each variable. The order is
one specified by the <code>symbol</code> class variable, see below.</p>
<p>The correlation function A is calculated as a statistical average
over several time origins in the trajectory <code>trj</code>. The <code>norigins</code>
variable can be used to tune the number of time origins used to
carry out the average. <code>norigins</code> can take the following values:</p>
<ul>
<li><code>norigins=-1</code>: all origins are used</li>
<li>an integer &gt;= 1: use only <code>n_origins</code> time origins</li>
<li>a float in the interval (0,1): use only a fraction <code>norigins</code> of frames as time origins</li>
<li><code>None</code>: a heuristics is used to keep the product of steps times particles constant</li>
</ul>
<p>Subclasses must provide a symbolic expression of the correlation
function through the <code>symbol</code> class variable. The following
convention is used: if a correlation function A depends on
variables x and y, then <code>symbol = 'A(x,y)'</code>.</p>
<p>The <code>phasespace</code> variable allow subclasses to access a list of 2d
numpy arrays with particles coordinates via the following private
variables:</p>
<ul>
<li>
<p>if <code>nbodies</code> is 1: <code>self._pos</code> for positions, <code>self._vel</code> for
velocities, <code>self._unf_pos</code> for PBC-unfolded positions</p>
</li>
<li>
<p>if <code>nbodies</code> is 2, an additional suffix that take values 0 or 1
is added to distinguish the two sets of particles,
e.g. <code>self._pos_0</code> and <code>self._pos_1</code></p>
</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Correlation(object):
    &#34;&#34;&#34;
    Base class for correlation functions.

    The correlation function is calculated for the trajectory `trj`. This can be:

    - an object implementing the atooms `Trajectory` interface
    - the path to a trajectory file in a format recognized by atooms

    A correlation function A(x) is defined over a grid of real
    entries {x_i} given by the list `grid`. To each entry of the grid,
    the correlation function has a corresponding value A_i=A(x_i). The
    latter values are stored in the `value` list.

    Correlation functions that depend on several variables, A(x,y,...)
    must provide a list of grids, one for each variable. The order is
    one specified by the `symbol` class variable, see below.

    The correlation function A is calculated as a statistical average
    over several time origins in the trajectory `trj`. The `norigins`
    variable can be used to tune the number of time origins used to
    carry out the average. `norigins` can take the following values:

    - `norigins=-1`: all origins are used
    - an integer &gt;= 1: use only `n_origins` time origins
    - a float in the interval (0,1): use only a fraction `norigins` of frames as time origins
    - `None`: a heuristics is used to keep the product of steps times particles constant

    Subclasses must provide a symbolic expression of the correlation
    function through the `symbol` class variable. The following
    convention is used: if a correlation function A depends on
    variables x and y, then `symbol = &#39;A(x,y)&#39;`.

    The `phasespace` variable allow subclasses to access a list of 2d
    numpy arrays with particles coordinates via the following private
    variables:

    - if `nbodies` is 1: `self._pos` for positions, `self._vel` for
    velocities, `self._unf_pos` for PBC-unfolded positions

    - if `nbodies` is 2, an additional suffix that take values 0 or 1
    is added to distinguish the two sets of particles,
    e.g. `self._pos_0` and `self._pos_1`
    &#34;&#34;&#34;

    nbodies = 1
    &#34;&#34;&#34;
    Class variable that controls the number of bodies, i.e. particles,
    associated to the correlation function. This variable controls the
    internal arrays used to compute the correlation, see `phasespace`.
    &#34;&#34;&#34;
    static = False
    &#34;&#34;&#34;
    Turn this to `True` is the correlation function is static,
    i.e. not time-dependent. This may enable some optimizations.
    &#34;&#34;&#34;
    symbol = &#39;&#39;
    &#34;&#34;&#34;Example: fskt&#34;&#34;&#34;
    short_name = &#39;&#39;
    &#34;&#34;&#34;Example: F_s(k,t)&#34;&#34;&#34;
    long_name = &#39;&#39;
    &#34;&#34;&#34;Example: Self intermediate scattering function&#34;&#34;&#34;
    phasespace = [&#39;pos&#39;, &#39;pos-unf&#39;, &#39;vel&#39;]
    &#34;&#34;&#34;
    List of strings or string among [&#39;pos&#39;, &#39;pos-unf&#39;, &#39;vel&#39;]. It
    indicates which variables should be read from the trajectory file.
    They will be available as self._pos, self._pos_unf, self._vel.
    &#34;&#34;&#34;
    _symmetric = True
    &#34;&#34;&#34;
    If nbodies&gt;1, a symmetric correlation function is invariant under
    the exchange between _pos_0 and _pos_1. In that case, _symmetric
    is True.
    &#34;&#34;&#34;

    def __init__(self, trj, grid, output_path=None, norigins=None, fix_cm=False):
        # Accept a trajectory-like instance or a path to a trajectory
        if isinstance(trj, str):
            self.trajectory = Trajectory(trj, mode=&#39;r&#39;, fmt=core.pp_trajectory_format)
        else:
            self.trajectory = trj
        self._fix_cm = fix_cm
        self._unfolded = None
        self.grid = grid
        self.value = []
        self.analysis = {}
        self.comments = None  # can be modified by user at run time
        self.tag = &#39;&#39;
        self.tag_description = &#39;the whole system&#39;
        if self.trajectory.filename is None:
            self.output_path = None
        else:
            self.output_path = output_path if output_path is not None else core.pp_output_path
        self.skip = adjust_skip(self.trajectory, norigins)

        # Callbacks
        self._cbk = []
        self._cbk_args = []
        self._cbk_kwargs = []

        # Lists for one body correlations
        self._pos = []
        self._vel = []
        self._ids = []
        self._pos_unf = []

        # Lists for two-body correlations
        self._pos_0, self._pos_1 = [], []
        self._vel_0, self._vel_1 = [], []
        self._ids_0, self._ids_1 = [], []
        self._pos_unf_0, self._pos_unf_1 = [], []

        # Weights
        self._weight = None
        self._weight_0, self._weight_1 = None, None
        self._weight_field = None
        self._weight_fluctuations = False

    def __str__(self):
        return &#39;{} at &lt;{}&gt;&#39;.format(self.long_name, id(self))

    def add_weight(self, trajectory=None, field=None, fluctuations=False):
        &#34;&#34;&#34;
        Add weight from the given `field` in `trajectory`

        If `trajectory` is `None`, `self.trajectory` will be used and
        `field` must be a particle property.

        If `field` is `None`, `trajectory` is assumed to be a path an
        xyz trajectory and we use the data in last column as a weight.

        If both `field` and `trajectory` are `None` the function
        returns immediately and the weight is not set.

        The optional `fluctuations` option subtracts the mean,
        calculated from the ensemble average, from the weight.
        &#34;&#34;&#34;
        if trajectory is None and field is None:
            return

        self._weight = []
        self._weight_fluctuations = fluctuations

        # Guessing the field from the last column of an xyz file is
        # not supported anymore
        if field is None:
            raise ValueError(&#39;provide field to use as weight&#39;)
        else:
            self._weight_field = field

        # By default we use the same trajectory as for the phasespace
        if trajectory is None:
            self._weight_trajectory = self.trajectory
        else:
            self._weight_trajectory = trajectory
            # Copy over the field
            from .helpers import copy_field
            self.trajectory.add_callback(copy_field, self._weight_field, self._weight_trajectory)

        # Make sure the steps are consistent
        if self._weight_trajectory.steps != self.trajectory.steps:
            raise ValueError(&#39;inconsistency between weight trajectory and trajectory&#39;)

        # Modify tag
        fluct = &#39;fluctuations&#39; if self._weight_fluctuations else &#39;&#39;
        self.tag_description += &#39; with {} {} field&#39;.format(self._weight_field.replace(&#39;_&#39;, &#39; &#39;), fluct)
        self.tag_description = self.tag_description.replace(&#39;  &#39;, &#39; &#39;)
        self.tag += &#39;.{}_{}&#39;.format(self._weight_field, fluct)
        self.tag.strip(&#39;_.&#39;)

    def add_filter(self, cbk, *args, **kwargs):
        &#34;&#34;&#34;Add filter callback `cbk` along with positional and keyword arguments&#34;&#34;&#34;
        if len(self._cbk) &gt; self.nbodies:
            raise ValueError(&#39;number of filters cannot exceed n. of bodies&#39;)
        self._cbk.append(cbk)
        self._cbk_args.append(args)
        self._cbk_kwargs.append(kwargs)

    def need_update(self):
        &#34;&#34;&#34;Check if the trajectory file is newer than the output file&#34;&#34;&#34;
        need = True
        if os.path.exists(self._output_file) and self._output_file != &#39;/dev/stdout&#39;:
            if os.path.getmtime(self.trajectory.filename) &lt; \
               os.path.getmtime(self._output_file):
                need = False
        return need

    def _setup_arrays(self):
        &#34;&#34;&#34;
        Dump positions and/or velocities at different time frames as a
        list of numpy array.
        &#34;&#34;&#34;
        # TODO: what happens if we call compute twice?? Shouldnt we reset the arrays?
        # Ensure phasespace is a list.
        # It may not be a class variable anymore after this
        if not isinstance(self.phasespace, list) and \
           not isinstance(self.phasespace, tuple):
            self.phasespace = [self.phasespace]

        # Setup arrays
        if self.nbodies == 1:
            self._setup_arrays_onebody()
            self._setup_weight_onebody()
        elif self.nbodies == 2:
            self._setup_arrays_twobody()
            self._setup_weight_twobody()

    def _setup_arrays_onebody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for one-body correlations.

        We also take care of dumping the weight if needed, see
        `add_weight()`.
        &#34;&#34;&#34;
        # Local shortcut
        th = self.trajectory

        # We unfold the trajectory if phasespace requests it and
        # unfolded positions are not available in the trajectory, or
        # if we request folded positions with fixed center of mass
        if (&#39;pos-unf&#39; in self.phasespace and not hasattr(th[0].particle[0], &#39;position_unfolded&#39;)) or \
           (&#39;pos&#39; in self.phasespace and self._fix_cm):
            # We unfold the positions, caching the trajectory
            if self._unfolded is None:
                self._unfolded = Unfolded(self.trajectory, fixed_cm=self._fix_cm)
                # We must fold positions back in this case
                if &#39;pos&#39; in self.phasespace:
                    self._unfolded.add_callback(fold)
            # Change the local shortcut to the unfolded trajectory
            th = self._unfolded

        # Read everything except unfolded trajectories
        if &#39;pos&#39; in self.phasespace or &#39;vel&#39; in self.phasespace or &#39;ids&#39; in self.phasespace:
            ids = distinct_species(th[0].particle)
            for s in progress(th):
                # Apply filter if there is one
                if len(self._cbk) &gt; 0:
                    s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                if &#39;pos&#39; in self.phasespace:
                    self._pos.append(s.dump(&#39;pos&#39;))
                if &#39;vel&#39; in self.phasespace:
                    self._vel.append(s.dump(&#39;vel&#39;))
                if &#39;ids&#39; in self.phasespace:
                    _ids = s.dump(&#39;species&#39;)
                    _ids = numpy.array([ids.index(_) for _ in _ids], dtype=numpy.int32)
                    self._ids.append(_ids)

        # Read unfolded positions if requested
        if &#39;pos-unf&#39; in self.phasespace:
            if hasattr(th[0].particle[0], &#39;position_unfolded&#39;):
                # Unfolded positions are present in the trajectory
                for s in progress(th):
                    # Fixing the CM must be done explicitly using
                    # particle.position_unfolded because atooms.system
                    # methods work with particle.position
                    # TODO: can be revised with atooms 3.4.0
                    if self._fix_cm:
                        # Compute CM using unfolded positions, which is safe
                        cm = numpy.zeros_like(s.particle[0].position_unfolded)
                        mtot = 0.0
                        for p in s.particle:
                            cm += p.position_unfolded * p.mass
                            mtot += p.mass
                        cm /= mtot
                        # Subtract it
                        for p in s.particle:
                            p.position_unfolded -= cm
                    # Apply filter if there is one
                    # This must be done after the CM has been fixed
                    if len(self._cbk) &gt; 0:
                        s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                    self._pos_unf.append(s.dump(&#39;particle.position_unfolded&#39;))
            else:
                for s in progress(th):
                    # Apply filter if there is one
                    if len(self._cbk) &gt; 0:
                        s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                    self._pos_unf.append(s.dump(&#39;pos&#39;))

    def _setup_weight_onebody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for the weight, see `add_weight()`
        &#34;&#34;&#34;
        if self._weight is None:
            return

        # Dump arrays of weights
        for s in progress(self.trajectory):
            # Apply filter if there is one
            # TODO: fix when weight trajectory does not contain actual particle info
            # It should be possible to link the weight trajectory to the trajectory
            # and return the trajectory particles with the weight
            if len(self._cbk) &gt; 0:
                s = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
            current_weight = s.dump(&#39;particle.%s&#39; % self._weight_field)
            self._weight.append(current_weight)

        # Subtract global mean
        if self._weight_fluctuations:
            _subtract_mean(self._weight)

    def _setup_weight_twobody(self):
        &#34;&#34;&#34;
        Setup list of numpy arrays for the weight, see `add_weight()`
        &#34;&#34;&#34;
        if self._weight is None:
            return

        self._weight = []
        self._weight_0 = []
        self._weight_1 = []

        # TODO: add checks on number of filters
        if len(self._cbk) &lt;= 1:
            self._setup_weight_onebody()
            self._weight_0 = self._weight
            self._weight_1 = self._weight
            return

        # Dump arrays of weights
        for s in progress(self.trajectory):
            # Apply filters
            if len(self._cbk) == 2:
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
            self._weight_0.append(s0.dump(&#39;particle.%s&#39; % self._weight_field))
            self._weight_1.append(s1.dump(&#39;particle.%s&#39; % self._weight_field))

        # Subtract global mean
        if self._weight_fluctuations:
            _subtract_mean(self._weight_0)
            _subtract_mean(self._weight_1)

    def _setup_arrays_twobody(self):
        &#34;&#34;&#34;Setup list of numpy arrays for two-body correlations.&#34;&#34;&#34;
        if len(self._cbk) &lt;= 1:
            self._setup_arrays_onebody()
            self._pos_0 = self._pos
            self._pos_1 = self._pos
            self._vel_0 = self._vel
            self._vel_1 = self._vel
            self._ids_0 = self._ids
            self._ids_1 = self._ids
            return

        if &#39;pos&#39; in self.phasespace or &#39;vel&#39; in self.phasespace or &#39;ids&#39; in self.phasespace:
            ids = distinct_species(self.trajectory[0].particle)
            for s in progress(self.trajectory):
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
                if &#39;pos&#39; in self.phasespace:
                    self._pos_0.append(s0.dump(&#39;pos&#39;))
                    self._pos_1.append(s1.dump(&#39;pos&#39;))
                if &#39;vel&#39; in self.phasespace:
                    self._vel_0.append(s0.dump(&#39;vel&#39;))
                    self._vel_1.append(s1.dump(&#39;vel&#39;))
                if &#39;ids&#39; in self.phasespace:
                    _ids_0 = s0.dump(&#39;species&#39;)
                    _ids_1 = s1.dump(&#39;species&#39;)
                    _ids_0 = numpy.array([ids.index(_) for _ in _ids_0], dtype=numpy.int32)
                    _ids_1 = numpy.array([ids.index(_) for _ in _ids_1], dtype=numpy.int32)
                    self._ids_0.append(_ids_0)
                    self._ids_1.append(_ids_1)

        # Dump unfolded positions if requested
        if &#39;pos-unf&#39; in self.phasespace:
            for s in progress(Unfolded(self.trajectory)):
                s0 = self._cbk[0](s, *self._cbk_args[0], **self._cbk_kwargs[0])
                s1 = self._cbk[1](s, *self._cbk_args[1], **self._cbk_kwargs[1])
                self._pos_unf_0.append(s0.dump(&#39;pos&#39;))
                self._pos_unf_1.append(s1.dump(&#39;pos&#39;))

    def compute(self):
        &#34;&#34;&#34;
        Compute the correlation function.

        It wraps the _compute() method implemented by subclasses.
        This method sets the `self.grid` and `self.value` variables,
        which are also returned.
        &#34;&#34;&#34;
        _log.info(&#39;setup arrays for %s&#39;, self.tag_description)
        t = [Timer(), Timer()]
        t[0].start()
        self._setup_arrays()
        t[0].stop()

        _log.info(&#39;computing %s for %s&#39;, self.long_name, self.tag_description)
        _log.info(&#39;using %s time origins out of %s&#39;,
                  len(range(0, len(self.trajectory), self.skip)),
                  len(self.trajectory))
        t[1].start()
        self._compute()
        t[1].stop()

        _log.info(&#39;output file %s&#39;, self._output_file)
        _log.info(&#39;done %s for %s in %.1f sec [setup:%.0f%%, compute: %.0f%%]&#39;,
                  self.long_name,
                  self.tag_description, t[0].wall_time + t[1].wall_time,
                  t[0].wall_time / (t[0].wall_time + t[1].wall_time) * 100,
                  t[1].wall_time / (t[0].wall_time + t[1].wall_time) * 100)
        _log.info(&#39;&#39;)

        return self.grid, self.value

    def _compute(self):
        &#34;&#34;&#34;Subclasses must implement this&#34;&#34;&#34;
        pass

    def analyze(self):
        &#34;&#34;&#34;
        Subclasses may implement this and store the results in the
        self.analysis dictonary
        &#34;&#34;&#34;
        pass

    @property
    def _output_file(self):
        &#34;&#34;&#34;Returns path of output file&#34;&#34;&#34;
        # Interpolate the output path string
        if self.output_path is None:
            filename = None
        else:
            filename = self.output_path.format(symbol=self.symbol,
                                               short_name=self.short_name,
                                               long_name=self.long_name.replace(&#39; &#39;, &#39;_&#39;),
                                               tag=self.tag,
                                               tag_description=self.tag_description.replace(&#39; &#39;, &#39;_&#39;),
                                               trajectory=self.trajectory)
            # Strip unpleasant punctuation from basename path
            for punct in [&#39;.&#39;, &#39;_&#39;, &#39;-&#39;]:
                subpaths = filename.split(&#39;/&#39;)
                subpaths[-1] = subpaths[-1].replace(punct * 2, punct)
                subpaths[-1] = subpaths[-1].strip(punct)
                filename = &#39;/&#39;.join(subpaths)
        return filename

    def read(self):
        &#34;&#34;&#34;Read correlation function from existing file&#34;&#34;&#34;
        with open(self._output_file, &#39;r&#39;) as inp:
            x = numpy.loadtxt(inp, unpack=True)
            if len(x) == 3:
                _log.warn(&#34;cannot read 3-columns files yet in %s&#34;, self._output_file)
            elif len(x) == 2:
                self.grid, self.value = x
            else:
                self.grid, self.value = x[0: 2]
                _log.warn(&#34;Ignoring some columns in %s&#34;, self._output_file)

    @property
    def grid_name(self):
        &#34;&#34;&#34;
        Return the name of the grid variables

        Example:
        -------
        If `self.name` is `F_s(k,t)`, the function returns `[&#39;k&#39;, &#39;t&#39;]`
        &#34;&#34;&#34;
        variables = self.short_name.split(&#39;(&#39;)[1][:-1]
        return variables.split(&#39;,&#39;)

    def write(self):
        &#34;&#34;&#34;
        Write the correlation function and the analysis data to file

        The `output_path` instance variable is used to define the
        output files by interpolating the following variables:

        - symbol
        - short_name
        - long_name
        - tag
        - tag_description
        - trajectory

        The default is defined by core.pp_output_path, which currently
        looks like &#39;{trajectory.filename}.pp.{symbol}.{tag}&#39;
        &#34;&#34;&#34;
        # Pack grid and value into arrays to dump
        if _is_iterable(self.grid[0]) and len(self.grid) == 2:
            x = numpy.array(self.grid[0]).repeat(len(self.value[0]))
            y = numpy.array(self.grid[1] * len(self.grid[0]))
            z = numpy.array(self.value).flatten()
            dump = numpy.transpose(numpy.array([x, y, z]))
        else:
            dump = numpy.transpose(numpy.array([self.grid, self.value]))

        # Comment line
        # Extract variables from parenthesis in symbol
        variables = self.short_name.split(&#39;(&#39;)[1][:-1]
        variables = variables.split(&#39;,&#39;)
        columns = variables + [self.short_name]  # [self.symbol]
        if len(self.tag_description) &gt; 0:
            conj = &#39;of&#39;
        else:
            conj = &#39;&#39;
        comments = _dump(title=&#39;%s %s %s %s&#39; % (self.long_name, self.short_name, conj, self.tag_description),
                         columns=columns,
                         command=&#39;atooms-pp&#39;, version=core.__version__,
                         description=None, note=None,
                         parents=self.trajectory.filename,
                         inline=False)
        if self.comments is not None:
            comments += self.comments

        # Results of analysis
        analysis = &#34;&#34;
        for x, f in self.analysis.items():
            if f is not None:
                analysis += &#39;# %s: %s\n&#39; % (x, f)

        # Put it all together
        # and make sure the path to the output file exists
        import os
        from atooms.core.utils import mkdir
        if self._output_file is not None:
            mkdir(os.path.dirname(self._output_file))
            with open(self._output_file, &#39;w&#39;) as fh:
                fh.write(comments)
                if len(analysis) &gt; 0:
                    fh.write(analysis)
                numpy.savetxt(fh, dump, fmt=&#34;%g&#34;)
                fh.flush()

    def do(self, update=False):
        &#34;&#34;&#34;
        Do the full template pattern: compute, analyze and write the
        correlation function.
        &#34;&#34;&#34;
        if update and not self.need_update():
            self.read()
            return

        self.compute()

        try:
            self.analyze()
        except ImportError as e:
            _log.warn(&#39;Could not analyze due to missing modules, continuing...&#39;)
            _log.warn(e)

        self.write()

    def __call__(self):
        self.do()

    def show(self, now=True):
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            return

        if not _is_iterable(self.grid[0]):
            plt.plot(self.grid, self.value)
            plt.ylabel(self.short_name)
            plt.xlabel(self.grid_name[0])
        if now:
            plt.show()</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="postprocessing.alpha2.NonGaussianParameter" href="alpha2.html#postprocessing.alpha2.NonGaussianParameter">NonGaussianParameter</a></li>
<li><a title="postprocessing.ba.BondAngleDistribution" href="ba.html#postprocessing.ba.BondAngleDistribution">BondAngleDistribution</a></li>
<li><a title="postprocessing.chi4t.Chi4SelfOverlap" href="chi4t.html#postprocessing.chi4t.Chi4SelfOverlap">Chi4SelfOverlap</a></li>
<li><a title="postprocessing.fourierspace.FourierSpaceCorrelation" href="fourierspace.html#postprocessing.fourierspace.FourierSpaceCorrelation">FourierSpaceCorrelation</a></li>
<li><a title="postprocessing.gr.RadialDistributionFunctionLegacy" href="gr.html#postprocessing.gr.RadialDistributionFunctionLegacy">RadialDistributionFunctionLegacy</a></li>
<li><a title="postprocessing.msd.MeanSquareDisplacement" href="msd.html#postprocessing.msd.MeanSquareDisplacement">MeanSquareDisplacement</a></li>
<li><a title="postprocessing.qt.CollectiveOverlap" href="qt.html#postprocessing.qt.CollectiveOverlap">CollectiveOverlap</a></li>
<li><a title="postprocessing.qt.SelfOverlap" href="qt.html#postprocessing.qt.SelfOverlap">SelfOverlap</a></li>
<li><a title="postprocessing.sacf.StressAutocorrelation" href="sacf.html#postprocessing.sacf.StressAutocorrelation">StressAutocorrelation</a></li>
<li><a title="postprocessing.susceptibility.Susceptibility" href="susceptibility.html#postprocessing.susceptibility.Susceptibility">Susceptibility</a></li>
<li><a title="postprocessing.vacf.VelocityAutocorrelation" href="vacf.html#postprocessing.vacf.VelocityAutocorrelation">VelocityAutocorrelation</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="postprocessing.correlation.Correlation.long_name"><code class="name">var <span class="ident">long_name</span></code></dt>
<dd>
<div class="desc"><p>Example: Self intermediate scattering function</p></div>
</dd>
<dt id="postprocessing.correlation.Correlation.nbodies"><code class="name">var <span class="ident">nbodies</span></code></dt>
<dd>
<div class="desc"><p>Class variable that controls the number of bodies, i.e. particles,
associated to the correlation function. This variable controls the
internal arrays used to compute the correlation, see <code>phasespace</code>.</p></div>
</dd>
<dt id="postprocessing.correlation.Correlation.phasespace"><code class="name">var <span class="ident">phasespace</span></code></dt>
<dd>
<div class="desc"><p>List of strings or string among ['pos', 'pos-unf', 'vel']. It
indicates which variables should be read from the trajectory file.
They will be available as self._pos, self._pos_unf, self._vel.</p></div>
</dd>
<dt id="postprocessing.correlation.Correlation.short_name"><code class="name">var <span class="ident">short_name</span></code></dt>
<dd>
<div class="desc"><p>Example: F_s(k,t)</p></div>
</dd>
<dt id="postprocessing.correlation.Correlation.static"><code class="name">var <span class="ident">static</span></code></dt>
<dd>
<div class="desc"><p>Turn this to <code>True</code> is the correlation function is static,
i.e. not time-dependent. This may enable some optimizations.</p></div>
</dd>
<dt id="postprocessing.correlation.Correlation.symbol"><code class="name">var <span class="ident">symbol</span></code></dt>
<dd>
<div class="desc"><p>Example: fskt</p></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="postprocessing.correlation.Correlation.grid_name"><code class="name">var <span class="ident">grid_name</span></code></dt>
<dd>
<div class="desc"><p>Return the name of the grid variables</p>
<h2 id="example">Example:</h2>
<p>If <code>self.name</code> is <code>F_s(k,t)</code>, the function returns <code>['k', 't']</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def grid_name(self):
    &#34;&#34;&#34;
    Return the name of the grid variables

    Example:
    -------
    If `self.name` is `F_s(k,t)`, the function returns `[&#39;k&#39;, &#39;t&#39;]`
    &#34;&#34;&#34;
    variables = self.short_name.split(&#39;(&#39;)[1][:-1]
    return variables.split(&#39;,&#39;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="postprocessing.correlation.Correlation.add_filter"><code class="name flex">
<span>def <span class="ident">add_filter</span></span>(<span>self, cbk, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Add filter callback <code>cbk</code> along with positional and keyword arguments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_filter(self, cbk, *args, **kwargs):
    &#34;&#34;&#34;Add filter callback `cbk` along with positional and keyword arguments&#34;&#34;&#34;
    if len(self._cbk) &gt; self.nbodies:
        raise ValueError(&#39;number of filters cannot exceed n. of bodies&#39;)
    self._cbk.append(cbk)
    self._cbk_args.append(args)
    self._cbk_kwargs.append(kwargs)</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.add_weight"><code class="name flex">
<span>def <span class="ident">add_weight</span></span>(<span>self, trajectory=None, field=None, fluctuations=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add weight from the given <code>field</code> in <code>trajectory</code></p>
<p>If <code>trajectory</code> is <code>None</code>, <code>self.trajectory</code> will be used and
<code>field</code> must be a particle property.</p>
<p>If <code>field</code> is <code>None</code>, <code>trajectory</code> is assumed to be a path an
xyz trajectory and we use the data in last column as a weight.</p>
<p>If both <code>field</code> and <code>trajectory</code> are <code>None</code> the function
returns immediately and the weight is not set.</p>
<p>The optional <code>fluctuations</code> option subtracts the mean,
calculated from the ensemble average, from the weight.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_weight(self, trajectory=None, field=None, fluctuations=False):
    &#34;&#34;&#34;
    Add weight from the given `field` in `trajectory`

    If `trajectory` is `None`, `self.trajectory` will be used and
    `field` must be a particle property.

    If `field` is `None`, `trajectory` is assumed to be a path an
    xyz trajectory and we use the data in last column as a weight.

    If both `field` and `trajectory` are `None` the function
    returns immediately and the weight is not set.

    The optional `fluctuations` option subtracts the mean,
    calculated from the ensemble average, from the weight.
    &#34;&#34;&#34;
    if trajectory is None and field is None:
        return

    self._weight = []
    self._weight_fluctuations = fluctuations

    # Guessing the field from the last column of an xyz file is
    # not supported anymore
    if field is None:
        raise ValueError(&#39;provide field to use as weight&#39;)
    else:
        self._weight_field = field

    # By default we use the same trajectory as for the phasespace
    if trajectory is None:
        self._weight_trajectory = self.trajectory
    else:
        self._weight_trajectory = trajectory
        # Copy over the field
        from .helpers import copy_field
        self.trajectory.add_callback(copy_field, self._weight_field, self._weight_trajectory)

    # Make sure the steps are consistent
    if self._weight_trajectory.steps != self.trajectory.steps:
        raise ValueError(&#39;inconsistency between weight trajectory and trajectory&#39;)

    # Modify tag
    fluct = &#39;fluctuations&#39; if self._weight_fluctuations else &#39;&#39;
    self.tag_description += &#39; with {} {} field&#39;.format(self._weight_field.replace(&#39;_&#39;, &#39; &#39;), fluct)
    self.tag_description = self.tag_description.replace(&#39;  &#39;, &#39; &#39;)
    self.tag += &#39;.{}_{}&#39;.format(self._weight_field, fluct)
    self.tag.strip(&#39;_.&#39;)</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.analyze"><code class="name flex">
<span>def <span class="ident">analyze</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclasses may implement this and store the results in the
self.analysis dictonary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analyze(self):
    &#34;&#34;&#34;
    Subclasses may implement this and store the results in the
    self.analysis dictonary
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.compute"><code class="name flex">
<span>def <span class="ident">compute</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the correlation function.</p>
<p>It wraps the _compute() method implemented by subclasses.
This method sets the <code>self.grid</code> and <code>self.value</code> variables,
which are also returned.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute(self):
    &#34;&#34;&#34;
    Compute the correlation function.

    It wraps the _compute() method implemented by subclasses.
    This method sets the `self.grid` and `self.value` variables,
    which are also returned.
    &#34;&#34;&#34;
    _log.info(&#39;setup arrays for %s&#39;, self.tag_description)
    t = [Timer(), Timer()]
    t[0].start()
    self._setup_arrays()
    t[0].stop()

    _log.info(&#39;computing %s for %s&#39;, self.long_name, self.tag_description)
    _log.info(&#39;using %s time origins out of %s&#39;,
              len(range(0, len(self.trajectory), self.skip)),
              len(self.trajectory))
    t[1].start()
    self._compute()
    t[1].stop()

    _log.info(&#39;output file %s&#39;, self._output_file)
    _log.info(&#39;done %s for %s in %.1f sec [setup:%.0f%%, compute: %.0f%%]&#39;,
              self.long_name,
              self.tag_description, t[0].wall_time + t[1].wall_time,
              t[0].wall_time / (t[0].wall_time + t[1].wall_time) * 100,
              t[1].wall_time / (t[0].wall_time + t[1].wall_time) * 100)
    _log.info(&#39;&#39;)

    return self.grid, self.value</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.do"><code class="name flex">
<span>def <span class="ident">do</span></span>(<span>self, update=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Do the full template pattern: compute, analyze and write the
correlation function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def do(self, update=False):
    &#34;&#34;&#34;
    Do the full template pattern: compute, analyze and write the
    correlation function.
    &#34;&#34;&#34;
    if update and not self.need_update():
        self.read()
        return

    self.compute()

    try:
        self.analyze()
    except ImportError as e:
        _log.warn(&#39;Could not analyze due to missing modules, continuing...&#39;)
        _log.warn(e)

    self.write()</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.need_update"><code class="name flex">
<span>def <span class="ident">need_update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if the trajectory file is newer than the output file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def need_update(self):
    &#34;&#34;&#34;Check if the trajectory file is newer than the output file&#34;&#34;&#34;
    need = True
    if os.path.exists(self._output_file) and self._output_file != &#39;/dev/stdout&#39;:
        if os.path.getmtime(self.trajectory.filename) &lt; \
           os.path.getmtime(self._output_file):
            need = False
    return need</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Read correlation function from existing file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self):
    &#34;&#34;&#34;Read correlation function from existing file&#34;&#34;&#34;
    with open(self._output_file, &#39;r&#39;) as inp:
        x = numpy.loadtxt(inp, unpack=True)
        if len(x) == 3:
            _log.warn(&#34;cannot read 3-columns files yet in %s&#34;, self._output_file)
        elif len(x) == 2:
            self.grid, self.value = x
        else:
            self.grid, self.value = x[0: 2]
            _log.warn(&#34;Ignoring some columns in %s&#34;, self._output_file)</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self, now=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(self, now=True):
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        return

    if not _is_iterable(self.grid[0]):
        plt.plot(self.grid, self.value)
        plt.ylabel(self.short_name)
        plt.xlabel(self.grid_name[0])
    if now:
        plt.show()</code></pre>
</details>
</dd>
<dt id="postprocessing.correlation.Correlation.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Write the correlation function and the analysis data to file</p>
<p>The <code>output_path</code> instance variable is used to define the
output files by interpolating the following variables:</p>
<ul>
<li>symbol</li>
<li>short_name</li>
<li>long_name</li>
<li>tag</li>
<li>tag_description</li>
<li>trajectory</li>
</ul>
<p>The default is defined by core.pp_output_path, which currently
looks like '{trajectory.filename}.pp.{symbol}.{tag}'</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self):
    &#34;&#34;&#34;
    Write the correlation function and the analysis data to file

    The `output_path` instance variable is used to define the
    output files by interpolating the following variables:

    - symbol
    - short_name
    - long_name
    - tag
    - tag_description
    - trajectory

    The default is defined by core.pp_output_path, which currently
    looks like &#39;{trajectory.filename}.pp.{symbol}.{tag}&#39;
    &#34;&#34;&#34;
    # Pack grid and value into arrays to dump
    if _is_iterable(self.grid[0]) and len(self.grid) == 2:
        x = numpy.array(self.grid[0]).repeat(len(self.value[0]))
        y = numpy.array(self.grid[1] * len(self.grid[0]))
        z = numpy.array(self.value).flatten()
        dump = numpy.transpose(numpy.array([x, y, z]))
    else:
        dump = numpy.transpose(numpy.array([self.grid, self.value]))

    # Comment line
    # Extract variables from parenthesis in symbol
    variables = self.short_name.split(&#39;(&#39;)[1][:-1]
    variables = variables.split(&#39;,&#39;)
    columns = variables + [self.short_name]  # [self.symbol]
    if len(self.tag_description) &gt; 0:
        conj = &#39;of&#39;
    else:
        conj = &#39;&#39;
    comments = _dump(title=&#39;%s %s %s %s&#39; % (self.long_name, self.short_name, conj, self.tag_description),
                     columns=columns,
                     command=&#39;atooms-pp&#39;, version=core.__version__,
                     description=None, note=None,
                     parents=self.trajectory.filename,
                     inline=False)
    if self.comments is not None:
        comments += self.comments

    # Results of analysis
    analysis = &#34;&#34;
    for x, f in self.analysis.items():
        if f is not None:
            analysis += &#39;# %s: %s\n&#39; % (x, f)

    # Put it all together
    # and make sure the path to the output file exists
    import os
    from atooms.core.utils import mkdir
    if self._output_file is not None:
        mkdir(os.path.dirname(self._output_file))
        with open(self._output_file, &#39;w&#39;) as fh:
            fh.write(comments)
            if len(analysis) &gt; 0:
                fh.write(analysis)
            numpy.savetxt(fh, dump, fmt=&#34;%g&#34;)
            fh.flush()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="postprocessing" href="index.html">postprocessing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="postprocessing.correlation.acf" href="#postprocessing.correlation.acf">acf</a></code></li>
<li><code><a title="postprocessing.correlation.gcf" href="#postprocessing.correlation.gcf">gcf</a></code></li>
<li><code><a title="postprocessing.correlation.gcf_offset" href="#postprocessing.correlation.gcf_offset">gcf_offset</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="postprocessing.correlation.Correlation" href="#postprocessing.correlation.Correlation">Correlation</a></code></h4>
<ul class="two-column">
<li><code><a title="postprocessing.correlation.Correlation.add_filter" href="#postprocessing.correlation.Correlation.add_filter">add_filter</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.add_weight" href="#postprocessing.correlation.Correlation.add_weight">add_weight</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.analyze" href="#postprocessing.correlation.Correlation.analyze">analyze</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.compute" href="#postprocessing.correlation.Correlation.compute">compute</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.do" href="#postprocessing.correlation.Correlation.do">do</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.grid_name" href="#postprocessing.correlation.Correlation.grid_name">grid_name</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.long_name" href="#postprocessing.correlation.Correlation.long_name">long_name</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.nbodies" href="#postprocessing.correlation.Correlation.nbodies">nbodies</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.need_update" href="#postprocessing.correlation.Correlation.need_update">need_update</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.phasespace" href="#postprocessing.correlation.Correlation.phasespace">phasespace</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.read" href="#postprocessing.correlation.Correlation.read">read</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.short_name" href="#postprocessing.correlation.Correlation.short_name">short_name</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.show" href="#postprocessing.correlation.Correlation.show">show</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.static" href="#postprocessing.correlation.Correlation.static">static</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.symbol" href="#postprocessing.correlation.Correlation.symbol">symbol</a></code></li>
<li><code><a title="postprocessing.correlation.Correlation.write" href="#postprocessing.correlation.Correlation.write">write</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>